{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa5a4b2-49fe-4a17-95b9-9ef3bfefb67d",
   "metadata": {},
   "source": [
    "## Test SciBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0e232a-f387-4bbc-a33c-3e0239fcb9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashsemlani/anaconda3/envs/hophacks/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/yashsemlani/anaconda3/envs/hophacks/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0cf055f-ca4c-422d-a5be-d168bfc6b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Transformers have their pros and cons but are ultimately a great tool for scientific research.\n",
      "Predicted sentiment: POS\n",
      "Confidence: 0.9802\n",
      "The text expresses a positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "sample_text = \"Transformers have their pros and cons but are ultimately a great tool for scientific research.\"\n",
    "\n",
    "# Load tokenizer and model for text classification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "# Create sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Perform sentiment analysis\n",
    "result = sentiment_pipeline(sample_text)[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Input text: {sample_text}\")\n",
    "print(f\"Predicted sentiment: {result['label']}\")\n",
    "print(f\"Confidence: {result['score']:.4f}\")\n",
    "\n",
    "# Optionally, you can add more detailed interpretation\n",
    "if result['label'] == 'POS':\n",
    "    print(\"The text expresses a positive sentiment.\")\n",
    "elif result['label'] == 'NEG':\n",
    "    print(\"The text expresses a negative sentiment.\")\n",
    "else:\n",
    "    print(\"The text expresses a neutral sentiment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44625f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'POS', 'score': 0.9898030757904053}, {'label': 'NEU', 'score': 0.008573689498007298}, {'label': 'NEG', 'score': 0.0016232132911682129}]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"YOUR TEXT HERE\",\n",
    "})\n",
    "\n",
    "# Send the request and get the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ff7c542",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2620709366.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    git config --global --unset pull.rebase\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "git config --global --unset pull.rebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ed1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df05fe9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2942028750.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    git config --global pull.rebase false\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
